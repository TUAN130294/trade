{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# VN-Quant Stockformer Training\n",
        "**Train 102 Vietnamese stock prediction models on Google Colab**\n",
        "\n",
        "## Setup\n",
        "1. Runtime > Change runtime type > GPU (T4/V100/A100)\n",
        "2. Mount Google Drive\n",
        "3. Upload data from host server\n",
        "4. Run training\n",
        "5. Download models back to host"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check GPU\n",
        "!nvidia-smi\n",
        "import torch\n",
        "print(f\"\\nPyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project folder\n",
        "!mkdir -p /content/drive/MyDrive/VNQuant/data\n",
        "!mkdir -p /content/drive/MyDrive/VNQuant/models\n",
        "!mkdir -p /content/drive/MyDrive/VNQuant/checkpoints"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Install dependencies\n",
        "!pip install pandas numpy torch scikit-learn pyarrow tqdm -q"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define Stockformer Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=100):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class StockformerSimple(nn.Module):\n",
        "    def __init__(self, input_dim=5, d_model=64, nhead=4, num_layers=2, \n",
        "                 dim_feedforward=128, dropout=0.1, forecast_days=5):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output_proj = nn.Linear(d_model, forecast_days)\n",
        "        self.forecast_days = forecast_days\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer(x)\n",
        "        x = x[:, -1, :]\n",
        "        return self.output_proj(x)\n",
        "\n",
        "print(\"Model defined!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Training Functions\n",
        "def prepare_data(df, seq_len=20):\n",
        "    \"\"\"Prepare sequences for training\"\"\"\n",
        "    features = ['open', 'high', 'low', 'close', 'volume']\n",
        "    data = df[features].values\n",
        "    \n",
        "    # Normalize\n",
        "    mean = data.mean(axis=0)\n",
        "    std = data.std(axis=0) + 1e-8\n",
        "    data_norm = (data - mean) / std\n",
        "    \n",
        "    X, y = [], []\n",
        "    for i in range(len(data_norm) - seq_len - 5):\n",
        "        X.append(data_norm[i:i+seq_len])\n",
        "        # Target: 5-day returns\n",
        "        future_close = data[i+seq_len:i+seq_len+5, 3]  # close prices\n",
        "        current_close = data[i+seq_len-1, 3]\n",
        "        returns = (future_close - current_close) / current_close * 100\n",
        "        y.append(returns)\n",
        "    \n",
        "    return np.array(X), np.array(y), {'mean': mean, 'std': std}\n",
        "\n",
        "def train_model(symbol, data_path, save_path, epochs=100, batch_size=32):\n",
        "    \"\"\"Train model for one symbol\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    # Load data\n",
        "    df = pd.read_parquet(data_path)\n",
        "    if len(df) < 50:\n",
        "        return {'symbol': symbol, 'success': False, 'error': 'Insufficient data'}\n",
        "    \n",
        "    # Prepare\n",
        "    X, y, norm_params = prepare_data(df)\n",
        "    if len(X) < 20:\n",
        "        return {'symbol': symbol, 'success': False, 'error': 'Insufficient sequences'}\n",
        "    \n",
        "    # Split\n",
        "    split = int(len(X) * 0.8)\n",
        "    X_train, X_val = X[:split], X[split:]\n",
        "    y_train, y_val = y[:split], y[split:]\n",
        "    \n",
        "    # Tensors\n",
        "    X_train = torch.FloatTensor(X_train).to(device)\n",
        "    y_train = torch.FloatTensor(y_train).to(device)\n",
        "    X_val = torch.FloatTensor(X_val).to(device)\n",
        "    y_val = torch.FloatTensor(y_val).to(device)\n",
        "    \n",
        "    # Model\n",
        "    model = StockformerSimple().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "    \n",
        "    best_val_loss = float('inf')\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        # Mini-batch training\n",
        "        perm = torch.randperm(len(X_train))\n",
        "        total_loss = 0\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            idx = perm[i:i+batch_size]\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(X_train[idx])\n",
        "            loss = criterion(pred, y_train[idx])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_pred = model(X_val)\n",
        "            val_loss = criterion(val_pred, y_val).item()\n",
        "        \n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'norm_params': norm_params,\n",
        "                'val_loss': val_loss\n",
        "            }, save_path)\n",
        "    \n",
        "    return {\n",
        "        'symbol': symbol,\n",
        "        'success': True,\n",
        "        'val_loss': best_val_loss,\n",
        "        'samples': len(X)\n",
        "    }\n",
        "\n",
        "print(\"Training functions ready!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. List available stock data\n",
        "DATA_DIR = Path('/content/drive/MyDrive/VNQuant/data')\n",
        "MODEL_DIR = Path('/content/drive/MyDrive/VNQuant/models')\n",
        "\n",
        "parquet_files = list(DATA_DIR.glob('*.parquet'))\n",
        "symbols = [f.stem for f in parquet_files]\n",
        "\n",
        "print(f\"Found {len(symbols)} stocks to train\")\n",
        "print(f\"Symbols: {symbols[:20]}...\" if len(symbols) > 20 else f\"Symbols: {symbols}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. TRAIN ALL MODELS\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"Starting training at {datetime.now()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(f\"Stocks: {len(symbols)}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = []\n",
        "start_time = datetime.now()\n",
        "\n",
        "for i, symbol in enumerate(tqdm(symbols, desc=\"Training\")):\n",
        "    data_path = DATA_DIR / f\"{symbol}.parquet\"\n",
        "    save_path = MODEL_DIR / f\"{symbol}_stockformer_simple_best.pt\"\n",
        "    \n",
        "    result = train_model(symbol, data_path, save_path, epochs=100, batch_size=64)\n",
        "    results.append(result)\n",
        "    \n",
        "    if (i + 1) % 10 == 0:\n",
        "        success = len([r for r in results if r['success']])\n",
        "        print(f\"\\nProgress: {i+1}/{len(symbols)} | Success: {success}\")\n",
        "\n",
        "# Summary\n",
        "duration = (datetime.now() - start_time).total_seconds() / 3600\n",
        "successful = [r for r in results if r['success']]\n",
        "failed = [r for r in results if not r['success']]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Duration: {duration:.1f} hours\")\n",
        "print(f\"Success: {len(successful)}/{len(symbols)}\")\n",
        "print(f\"Failed: {len(failed)}\")\n",
        "\n",
        "if failed:\n",
        "    print(f\"Failed symbols: {[r['symbol'] for r in failed]}\")\n",
        "\n",
        "# Save results\n",
        "with open(MODEL_DIR / 'training_results.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'date': datetime.now().isoformat(),\n",
        "        'duration_hours': duration,\n",
        "        'total': len(symbols),\n",
        "        'success': len(successful),\n",
        "        'failed': len(failed),\n",
        "        'results': results\n",
        "    }, f, indent=2)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Verify trained models\n",
        "trained_models = list(MODEL_DIR.glob('*_stockformer_simple_best.pt'))\n",
        "print(f\"\\nTrained models saved: {len(trained_models)}\")\n",
        "print(f\"Location: {MODEL_DIR}\")\n",
        "print(\"\\nDownload these models to your host server's models/ folder\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
