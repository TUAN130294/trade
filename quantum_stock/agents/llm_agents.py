# -*- coding: utf-8 -*-
"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    LLM-POWERED AUTONOMOUS AGENTS                             ‚ïë
‚ïë                    Real AI Decision Making with Gemini/OpenAI               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

Agents th·ª±c s·ª± "suy nghƒ©" b·∫±ng AI, kh√¥ng ph·∫£i rule-based
"""

import os
import asyncio
import aiohttp
import json
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
from dataclasses import dataclass

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================
# LLM CLIENT
# ============================================

class LLMClient:
    """
    Universal LLM Client - routes through CCS proxy (Claudible provider)

    Default: CCS proxy at localhost:8317 with Claude Sonnet 4.6
    Also supports direct OpenAI/Anthropic API if needed
    """

    def __init__(self,
                 api_key: str = None,
                 base_url: str = None,
                 model: str = None,
                 provider: str = "claudible"):
        """
        Initialize LLM client

        Args:
            api_key: API key (or from env: LLM_API_KEY)
            base_url: Base URL (or from env: LLM_BASE_URL)
            model: Model name (or from env: LLM_MODEL)
            provider: "claudible" (CCS proxy), "openai", "claude"
        """
        self.api_key = api_key or os.getenv('LLM_API_KEY', '')
        self.provider = provider

        # Default: CCS proxy with Claudible (Claude Sonnet 4.6)
        if provider == "claudible":
            self.base_url = base_url or os.getenv('LLM_BASE_URL', 'http://localhost:8317/v1')
            self.model = model or os.getenv('LLM_MODEL', 'claude-sonnet-4-6')
        elif provider == "openai":
            self.base_url = base_url or os.getenv('LLM_BASE_URL', 'https://api.openai.com/v1')
            self.model = model or os.getenv('LLM_MODEL', 'gpt-4o-mini')
        elif provider == "claude":
            self.base_url = base_url or os.getenv('LLM_BASE_URL', 'https://api.anthropic.com/v1')
            self.model = model or os.getenv('LLM_MODEL', 'claude-sonnet-4-6')
        else:
            self.base_url = base_url or os.getenv('LLM_BASE_URL', 'http://localhost:8317/v1')
            self.model = model or os.getenv('LLM_MODEL', 'claude-sonnet-4-6')
        
        self.headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.api_key}'
        }
        
        logger.info(f"LLM Client initialized: {self.provider} @ {self.base_url}")
    
    async def chat(self, messages: List[Dict], 
                   temperature: float = 0.7,
                   max_tokens: int = 1000) -> str:
        """
        Send chat completion request
        
        Args:
            messages: List of {"role": "user/assistant/system", "content": "..."}
            temperature: Creativity (0-1)
            max_tokens: Max response length
        
        Returns:
            Response text
        """
        if not self.api_key:
            logger.warning("No API key configured, using mock response")
            return self._mock_response(messages)
        
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": self.model,
                    "messages": messages,
                    "temperature": temperature,
                    "max_tokens": max_tokens
                }
                
                url = f"{self.base_url}/chat/completions"
                
                async with session.post(url, json=payload, headers=self.headers, timeout=30) as response:
                    if response.status == 200:
                        data = await response.json()
                        return data['choices'][0]['message']['content']
                    else:
                        error = await response.text()
                        logger.error(f"LLM API error: {response.status} - {error}")
                        return self._mock_response(messages)
                        
        except asyncio.TimeoutError:
            logger.error("LLM API timeout")
            return self._mock_response(messages)
        except Exception as e:
            logger.error(f"LLM API error: {e}")
            return self._mock_response(messages)
    
    def _mock_response(self, messages: List[Dict]) -> str:
        """Fallback mock response when API unavailable"""
        last_msg = messages[-1]['content'] if messages else ""
        
        if "ph√¢n t√≠ch" in last_msg.lower() or "analyze" in last_msg.lower():
            return "D·ª±a tr√™n ph√¢n t√≠ch k·ªπ thu·∫≠t, RSI ƒëang ·ªü v√πng trung t√≠nh (50-55), MACD cho t√≠n hi·ªáu neutral. Khuy·∫øn ngh·ªã: WATCH v·ªõi confidence 65%."
        elif "mua" in last_msg.lower() or "buy" in last_msg.lower():
            return "C·ªï phi·∫øu c√≥ ti·ªÅm nƒÉng tƒÉng ng·∫Øn h·∫°n. Momentum t√≠ch c·ª±c nh∆∞ng c·∫ßn x√°c nh·∫≠n th√™m t·ª´ volume. Khuy·∫øn ngh·ªã: BUY v·ªõi confidence 70%."
        elif "b√°n" in last_msg.lower() or "sell" in last_msg.lower():
            return "C√≥ d·∫•u hi·ªáu ƒëi·ªÅu ch·ªânh. RSI overbought. Khuy·∫øn ngh·ªã: SELL m·ªôt ph·∫ßn v·ªõi confidence 60%."
        else:
            return "Th·ªã tr∆∞·ªùng ƒëang trong giai ƒëo·∫°n t√≠ch l≈©y. C·∫ßn theo d√µi th√™m."


# ============================================
# AI-POWERED AGENTS
# ============================================

@dataclass
class AgentPersonality:
    """Agent's personality and role"""
    name: str
    emoji: str
    role: str
    system_prompt: str
    bias: str  # bullish, bearish, neutral


# Agent Personalities
AGENT_PERSONALITIES = {
    "Alex": AgentPersonality(
        name="Alex",
        emoji="üìä",
        role="Technical Analyst",
        system_prompt="""B·∫°n l√† Alex, m·ªôt chuy√™n gia ph√¢n t√≠ch k·ªπ thu·∫≠t cho th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam.
        
Nhi·ªám v·ª•:
- Ph√¢n t√≠ch c√°c ch·ªâ b√°o k·ªπ thu·∫≠t: RSI, MACD, Bollinger Bands, Moving Averages
- ƒê√°nh gi√° xu h∆∞·ªõng gi√° v√† volume
- ƒê∆∞a ra khuy·∫øn ngh·ªã BUY/SELL/HOLD v·ªõi confidence (%)

Phong c√°ch:
- D·ª±a tr√™n d·ªØ li·ªáu, kh√¥ng c·∫£m t√≠nh
- Lu√¥n ƒë·ªÅ c·∫≠p ƒë·∫øn c√°c ch·ªâ b√°o c·ª• th·ªÉ
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch

Format tr·∫£ l·ªùi:
"B√°o c√°o Chief! [SYMBOL] ƒëang [t√¨nh tr·∫°ng]. [Ph√¢n t√≠ch ng·∫Øn]. Confidence [X]%."
""",
        bias="neutral"
    ),
    
    "Bull": AgentPersonality(
        name="Bull",
        emoji="üêÇ",
        role="Bullish Advocate",
        system_prompt="""B·∫°n l√† Bull, m·ªôt trader l·∫°c quan chuy√™n t√¨m c∆° h·ªôi mua.

Nhi·ªám v·ª•:
- T√¨m ƒëi·ªÉm mua t·ªët
- Nh√¨n th·∫•y c∆° h·ªôi trong m·ªçi t√¨nh hu·ªëng
- ·ª¶ng h·ªô c√°c v·ªã th·∫ø long

Phong c√°ch:
- Nhi·ªát t√¨nh, l·∫°c quan
- T·∫≠p trung v√†o ti·ªÅm nƒÉng tƒÉng gi√°
- N√≥i ng·∫Øn g·ªçn, ƒë·∫ßy nƒÉng l∆∞·ª£ng

Format tr·∫£ l·ªùi:
"[Emoji] [Nh·∫≠n x√©t ng·∫Øn v·ªÅ c∆° h·ªôi mua]! N√™n MUA th√¥i team!"
""",
        bias="bullish"
    ),
    
    "Bear": AgentPersonality(
        name="Bear",
        emoji="üêª",
        role="Risk Assessor",
        system_prompt="""B·∫°n l√† Bear, m·ªôt nh√† qu·∫£n l√Ω r·ªßi ro th·∫≠n tr·ªçng.

Nhi·ªám v·ª•:
- C·∫£nh b√°o r·ªßi ro
- T√¨m ƒëi·ªÉm y·∫øu, v√πng kh√°ng c·ª±
- ƒê·ªÅ xu·∫•t b√°n ho·∫∑c gi·ªØ ti·ªÅn m·∫∑t

Phong c√°ch:
- Th·∫≠n tr·ªçng, b·∫£o th·ªß
- T·∫≠p trung v√†o downside risk
- C·∫£nh b√°o khi th·∫•y nguy hi·ªÉm

Format tr·∫£ l·ªùi:
"[C·∫£nh b√°o r·ªßi ro ng·∫Øn g·ªçn]. C·∫©n th·∫≠n team!"
""",
        bias="bearish"
    ),
    
    "Chief": AgentPersonality(
        name="Chief",
        emoji="üëî",
        role="Decision Maker",
        system_prompt="""B·∫°n l√† Chief, ng∆∞·ªùi ƒë∆∞a ra quy·∫øt ƒë·ªãnh cu·ªëi c√πng.

Nhi·ªám v·ª•:
- T·ªïng h·ª£p √Ω ki·∫øn t·ª´ Alex, Bull, Bear
- C√¢n nh·∫Øc risk/reward
- ƒê∆∞a ra VERDICT cu·ªëi c√πng

Phong c√°ch:
- ƒêi·ªÅm ƒë·∫°m, quy·∫øt ƒëo√°n
- C√¢n b·∫±ng c√°c quan ƒëi·ªÉm
- Ra quy·∫øt ƒë·ªãnh r√µ r√†ng

Format tr·∫£ l·ªùi:
"üèõÔ∏è VERDICT: [SYMBOL] ‚Üí [BUY/SELL/HOLD/WATCH]. [L√Ω do ng·∫Øn]. Confidence [X]%."
""",
        bias="neutral"
    )
}


class AIAgent:
    """
    AI-Powered Trading Agent
    
    Uses LLM for real decision making
    """
    
    def __init__(self, personality: AgentPersonality, llm_client: LLMClient):
        self.personality = personality
        self.llm = llm_client
        self.conversation_history: List[Dict] = []
    
    async def think(self, context: Dict) -> str:
        """
        Agent thinks about the market context and responds
        
        Args:
            context: Dict with market data, alerts, other agent opinions
        
        Returns:
            Agent's response/opinion
        """
        # Build prompt
        system_msg = self.personality.system_prompt
        
        user_msg = self._build_user_message(context)
        
        messages = [
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_msg}
        ]
        
        # Add conversation history for context
        messages.extend(self.conversation_history[-4:])  # Last 4 messages
        messages.append({"role": "user", "content": user_msg})
        
        # Get AI response
        response = await self.llm.chat(messages, temperature=0.7)
        
        # Save to history
        self.conversation_history.append({"role": "assistant", "content": response})
        
        return response
    
    def _build_user_message(self, context: Dict) -> str:
        """Build user message from context"""
        symbol = context.get('symbol', 'N/A')
        price = context.get('price', 0)
        change = context.get('change', 0)
        
        msg = f"Ph√¢n t√≠ch m√£ {symbol}:\n"
        msg += f"- Gi√° hi·ªán t·∫°i: {price:,.0f} VND\n"
        msg += f"- Thay ƒë·ªïi: {change:+.2f}%\n"
        
        if 'indicators' in context:
            msg += f"- RSI: {context['indicators'].get('rsi', 'N/A')}\n"
            msg += f"- MACD: {context['indicators'].get('macd', 'N/A')}\n"
        
        if 'other_opinions' in context:
            msg += "\n√ù ki·∫øn c√°c agent kh√°c:\n"
            for opinion in context['other_opinions']:
                msg += f"- {opinion}\n"
        
        msg += "\nB·∫°n nghƒ© sao?"
        
        return msg
    
    async def respond_to(self, message: str) -> str:
        """Respond to a direct message"""
        messages = [
            {"role": "system", "content": self.personality.system_prompt},
            {"role": "user", "content": message}
        ]
        
        return await self.llm.chat(messages)


# ============================================
# AI AGENT COORDINATOR
# ============================================

class AIAgentCoordinator:
    """
    Coordinates AI-powered agents for market analysis
    
    Flow:
    1. Scout detects opportunity
    2. Alex analyzes technically
    3. Bull gives bullish view
    4. Bear gives bearish view
    5. Chief makes final decision
    """
    
    def __init__(self, api_key: str = None, base_url: str = None, model: str = None):
        self.llm = LLMClient(api_key=api_key, base_url=base_url, model=model)
        
        self.agents = {
            name: AIAgent(personality, self.llm)
            for name, personality in AGENT_PERSONALITIES.items()
        }
        
        self.conversation_log: List[Dict] = []
    
    async def analyze_symbol(self, symbol: str, price: float, change: float,
                             indicators: Dict = None) -> List[Dict]:
        """
        Full agent team analysis of a symbol
        
        Returns list of agent messages
        """
        self.conversation_log = []
        
        context = {
            'symbol': symbol,
            'price': price,
            'change': change,
            'indicators': indicators or {}
        }
        
        # Step 1: Alex analyzes
        alex_opinion = await self.agents['Alex'].think(context)
        self._log("Alex", "üìä", alex_opinion, "SUCCESS")
        
        await asyncio.sleep(0.5)  # Simulate thinking time
        
        # Step 2: Bull gives opinion
        context['other_opinions'] = [f"Alex: {alex_opinion}"]
        bull_opinion = await self.agents['Bull'].think(context)
        self._log("Bull", "üêÇ", bull_opinion, "WARNING")
        
        await asyncio.sleep(0.5)
        
        # Step 3: Bear gives opinion
        context['other_opinions'].append(f"Bull: {bull_opinion}")
        bear_opinion = await self.agents['Bear'].think(context)
        self._log("Bear", "üêª", bear_opinion, "INFO")
        
        await asyncio.sleep(0.5)
        
        # Step 4: Chief makes decision
        context['other_opinions'] = [
            f"Alex: {alex_opinion}",
            f"Bull: {bull_opinion}",
            f"Bear: {bear_opinion}"
        ]
        chief_verdict = await self.agents['Chief'].think(context)
        self._log("Chief", "üëî", chief_verdict, "SUCCESS")
        
        return self.conversation_log
    
    def _log(self, sender: str, emoji: str, content: str, msg_type: str):
        """Log a message"""
        self.conversation_log.append({
            'time': datetime.now().strftime('%H:%M:%S'),
            'sender': sender,
            'emoji': emoji,
            'content': content,
            'type': msg_type
        })
        logger.info(f"{emoji} {sender}: {content}")
    
    async def ask_agent(self, agent_name: str, question: str) -> str:
        """Ask a specific agent a question"""
        if agent_name not in self.agents:
            return f"Agent {agent_name} not found"
        
        return await self.agents[agent_name].respond_to(question)


# ============================================
# CONFIGURATION
# ============================================

def configure_llm(api_key: str = None,
                  base_url: str = "http://localhost:8317/v1",
                  model: str = "claude-sonnet-4-6") -> LLMClient:
    """
    Configure LLM client with API settings

    Default: CCS proxy (Claudible) at localhost:8317

    Example:
        client = configure_llm(api_key="your-ccs-key")

    Or set environment variables:
        LLM_API_KEY=your-ccs-key
        LLM_BASE_URL=http://localhost:8317/v1
        LLM_MODEL=claude-sonnet-4-6
    """
    return LLMClient(api_key=api_key, base_url=base_url, model=model, provider="claudible")


# ============================================
# TESTING
# ============================================

async def test_ai_agents():
    """Test AI agents"""
    print("=" * 60)
    print("ü§ñ AI-POWERED AGENT SYSTEM TEST")
    print("=" * 60)
    
    # Check if API key is configured
    api_key = os.getenv('LLM_API_KEY', '')
    
    if not api_key:
        print("\n‚ö†Ô∏è  No LLM_API_KEY set. Running in MOCK mode.")
        print("   To use real AI, set: LLM_API_KEY=your-ccs-proxy-key")
        print("   Default: CCS proxy (Claudible) at localhost:8317\n")
    
    # Create coordinator
    coordinator = AIAgentCoordinator()
    
    # Analyze a symbol
    print("üìä Analyzing MWG...\n")
    
    messages = await coordinator.analyze_symbol(
        symbol="MWG",
        price=88000,
        change=2.5,
        indicators={'rsi': 55, 'macd': 0.3}
    )
    
    print("\n" + "=" * 60)
    print("üìù CONVERSATION LOG:")
    print("=" * 60)
    
    for msg in messages:
        emoji = msg.get('emoji', 'ü§ñ')
        sender = msg.get('sender', 'Agent')
        content = msg.get('content', '')
        print(f"\n{msg['time']} {emoji} {sender}:")
        print(f"   {content[:200]}...")
    
    print("\n‚úÖ Test complete!")
    
    if not api_key:
        print("\nüí° ƒê·ªÉ s·ª≠ d·ª•ng AI th·∫≠t:")
        print("   set LLM_API_KEY=your-ccs-proxy-key")
        print("   python -c \"from quantum_stock.agents.llm_agents import test_ai_agents; import asyncio; asyncio.run(test_ai_agents())\"")


if __name__ == "__main__":
    asyncio.run(test_ai_agents())
